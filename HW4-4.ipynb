{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including pandas, numpy, matplotlib, and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load TinyMNIST Data\n",
    "Load the TinyMNIST dataset from the CSV files using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TinyMNIST Data\n",
    "\n",
    "# Load the training data and labels\n",
    "train_data = pd.read_csv('trainData.csv', header=None)\n",
    "train_labels = pd.read_csv('trainLabels.csv', header=None)\n",
    "\n",
    "# Load the test data and labels\n",
    "test_data = pd.read_csv('testData.csv', header=None)\n",
    "test_labels = pd.read_csv('testLabels.csv', header=None)\n",
    "\n",
    "# Display the shapes of the loaded data\n",
    "print(f'Training data shape: {train_data.shape}')\n",
    "print(f'Training labels shape: {train_labels.shape}')\n",
    "print(f'Test data shape: {test_data.shape}')\n",
    "print(f'Test labels shape: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Preprocess the data, including normalization and splitting into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the split data\n",
    "print(f'Training data shape after split: {X_train.shape}')\n",
    "print(f'Validation data shape: {X_val.shape}')\n",
    "print(f'Training labels shape after split: {y_train.shape}')\n",
    "print(f'Validation labels shape: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Elimination Algorithm\n",
    "Implement the Backward Elimination algorithm to select features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Elimination Algorithm\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Initialize RFE with the Naive Bayes classifier and the number of features to select\n",
    "rfe = RFE(estimator=nb_classifier, n_features_to_select=1, step=1)\n",
    "\n",
    "# Fit RFE on the training data\n",
    "rfe.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Get the ranking of the features\n",
    "ranking = rfe.ranking_\n",
    "\n",
    "# Get the support mask of the selected features\n",
    "support = rfe.support_\n",
    "\n",
    "# Print the ranking of the features\n",
    "print(f'Feature ranking: {ranking}')\n",
    "\n",
    "# Print the selected features\n",
    "print(f'Selected features: {support}')\n",
    "\n",
    "# Transform the training and validation data to select the features\n",
    "X_train_selected = rfe.transform(X_train)\n",
    "X_val_selected = rfe.transform(X_val)\n",
    "\n",
    "# Train the Naive Bayes classifier on the selected features\n",
    "nb_classifier.fit(X_train_selected, y_train.values.ravel())\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = nb_classifier.predict(X_val_selected)\n",
    "\n",
    "# Calculate the accuracy on the validation set\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Validation accuracy with selected features: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Selection Algorithm\n",
    "Implement the Forward Selection algorithm to select features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Selection Algorithm\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Initialize Forward Selection with the Naive Bayes classifier\n",
    "forward_selector = SequentialFeatureSelector(nb_classifier, n_features_to_select=1, direction='forward')\n",
    "\n",
    "# Fit Forward Selection on the training data\n",
    "forward_selector.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Get the support mask of the selected features\n",
    "support_forward = forward_selector.get_support()\n",
    "\n",
    "# Print the selected features\n",
    "print(f'Selected features (Forward Selection): {support_forward}')\n",
    "\n",
    "# Transform the training and validation data to select the features\n",
    "X_train_selected_forward = forward_selector.transform(X_train)\n",
    "X_val_selected_forward = forward_selector.transform(X_val)\n",
    "\n",
    "# Train the Naive Bayes classifier on the selected features\n",
    "nb_classifier.fit(X_train_selected_forward, y_train.values.ravel())\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_forward = nb_classifier.predict(X_val_selected_forward)\n",
    "\n",
    "# Calculate the accuracy on the validation set\n",
    "accuracy_forward = accuracy_score(y_val, y_val_pred_forward)\n",
    "print(f'Validation accuracy with selected features (Forward Selection): {accuracy_forward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Optimal Classifier\n",
    "Use the Naive Bayes classifier to classify the data and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Optimal Classifier\n",
    "\n",
    "# Train the Naive Bayes classifier on the entire training data\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = nb_classifier.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy on the validation set\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Validation accuracy: {accuracy}')\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = nb_classifier.predict(test_data)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "test_accuracy = accuracy_score(test_labels, y_test_pred)\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot CCR vs Number of Selected Features\n",
    "Plot the Correct Classification Rate (CCR) against the number of selected features for both algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CCR vs Number of Selected Features\n",
    "\n",
    "# Initialize lists to store the number of features and corresponding CCRs for both algorithms\n",
    "num_features_backward = []\n",
    "ccr_backward = []\n",
    "num_features_forward = []\n",
    "ccr_forward = []\n",
    "\n",
    "# Backward Elimination\n",
    "for n_features in range(1, X_train.shape[1] + 1):\n",
    "    rfe = RFE(estimator=nb_classifier, n_features_to_select=n_features, step=1)\n",
    "    rfe.fit(X_train, y_train.values.ravel())\n",
    "    X_val_selected = rfe.transform(X_val)\n",
    "    y_val_pred = nb_classifier.predict(X_val_selected)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    num_features_backward.append(n_features)\n",
    "    ccr_backward.append(accuracy)\n",
    "\n",
    "# Forward Selection\n",
    "for n_features in range(1, X_train.shape[1] + 1):\n",
    "    forward_selector = SequentialFeatureSelector(nb_classifier, n_features_to_select=n_features, direction='forward')\n",
    "    forward_selector.fit(X_train, y_train.values.ravel())\n",
    "    X_val_selected_forward = forward_selector.transform(X_val)\n",
    "    y_val_pred_forward = nb_classifier.predict(X_val_selected_forward)\n",
    "    accuracy_forward = accuracy_score(y_val, y_val_pred_forward)\n",
    "    num_features_forward.append(n_features)\n",
    "    ccr_forward.append(accuracy_forward)\n",
    "\n",
    "# Plot the CCR vs Number of Selected Features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(num_features_backward, ccr_backward, label='Backward Elimination', marker='o')\n",
    "plt.plot(num_features_forward, ccr_forward, label='Forward Selection', marker='x')\n",
    "plt.xlabel('Number of Selected Features')\n",
    "plt.ylabel('Correct Classification Rate (CCR)')\n",
    "plt.title('CCR vs Number of Selected Features')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
